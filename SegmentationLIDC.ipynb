{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "language": "markdown",
        "id": "kMBIU0HYFADb"
      },
      "source": [
        "# Lung Segmentation Inference\n",
        "Use the trained Detectron2 model to segment and crop lung regions from CT images."
      ],
      "id": "kMBIU0HYFADb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4vEgw28FADe",
        "outputId": "08d9ef2f-3443-4d18-d99f-7ecf5341024e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-ygb65547\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-ygb65547\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 400a49c1ec11a18dd25aea3910507bc3bcd15794\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.0.1)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp311-cp311-linux_x86_64.whl size=6438248 sha256=4e5bc12f31761858234019bbd8df83b4063793595f549c59cfc973a5fb430680\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gbgg4i1c/wheels/17/d9/40/60db98e485aa9455d653e29d1046601ce96fe23647f60c1c5a\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=ba0edc7f2e7ff796a7b0c4b4e2c8c157a821fc6bdb1ae39782bc86dd2aeb7a62\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=48cbe77209dc14120630beb0ca133c5252c792d720ed7f7ac985f5abe3baf7e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-25.1.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "id": "Q4vEgw28FADe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruku4ZT2FADe",
        "outputId": "9b5a803a-861b-4bb7-b414-795d973c9c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "ruku4ZT2FADe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python",
        "id": "PH9DjnDLFADf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "import concurrent.futures\n",
        "import multiprocessing"
      ],
      "id": "PH9DjnDLFADf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python",
        "id": "wVGqQGTZFADf"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\n",
        "    'Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml'))\n",
        "cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/RGCI_Lung_Cancer/Lung_Segmentation/V13/LungSegmentationOutput/model_final.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.DEVICE = 'cuda'\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "id": "wVGqQGTZFADf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Images Segmentation"
      ],
      "metadata": {
        "id": "2XFsG0TULhnz"
      },
      "id": "2XFsG0TULhnz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python",
        "id": "r3Gb9uS3FADg"
      },
      "outputs": [],
      "source": [
        "input_dir = '/content/drive/MyDrive/RGCI_Lung_Cancer/LIDC-IDRI Dataset CT Images/CT/train/'\n",
        "output_dir = '/content/drive/MyDrive/LIDC-IDRI Dataset Segmented CT images/CT/train/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "id": "r3Gb9uS3FADg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZR5jaCXFADg",
        "outputId": "c8f8dec2-63ea-4d21-d352-f6bb34f34bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images processed.\n"
          ]
        }
      ],
      "source": [
        "for fname in os.listdir(input_dir):\n",
        "    if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_dir, fname)\n",
        "    img = cv2.imread(img_path)\n",
        "    outputs = predictor(img)\n",
        "    instances = outputs['instances'].to('cpu')\n",
        "    masks = instances.pred_masks.numpy()\n",
        "\n",
        "    base_name = os.path.splitext(fname)[0]\n",
        "\n",
        "    for idx, mask in enumerate(masks):\n",
        "        seg_img = img * mask[:, :, None]\n",
        "        out_path = os.path.join(output_dir, f\"{base_name}.png\")\n",
        "        cv2.imwrite(out_path, seg_img)\n",
        "\n",
        "print('All images processed.')"
      ],
      "id": "7ZR5jaCXFADg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Images Segmentation\n"
      ],
      "metadata": {
        "id": "wrS_USnYMc0J"
      },
      "id": "wrS_USnYMc0J"
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/drive/MyDrive/RGCI_Lung_Cancer/LIDC-IDRI Dataset CT Images/CT/val/'\n",
        "output_dir = '/content/drive/MyDrive/LIDC-IDRI Dataset Segmented CT images/CT/val/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "qTfZkZ6MIkdw"
      },
      "id": "qTfZkZ6MIkdw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in os.listdir(input_dir):\n",
        "    if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_dir, fname)\n",
        "    img = cv2.imread(img_path)\n",
        "    outputs = predictor(img)\n",
        "    instances = outputs['instances'].to('cpu')\n",
        "    masks = instances.pred_masks.numpy()\n",
        "\n",
        "    base_name = os.path.splitext(fname)[0]\n",
        "\n",
        "    for idx, mask in enumerate(masks):\n",
        "        seg_img = img * mask[:, :, None]\n",
        "        out_path = os.path.join(output_dir, f\"{base_name}.png\")\n",
        "        cv2.imwrite(out_path, seg_img)\n",
        "\n",
        "print('All images processed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9dZPxkKMsJd",
        "outputId": "fd5e34ed-6edd-464b-a2ac-bb26480ed06b"
      },
      "id": "F9dZPxkKMsJd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Images Segmentation"
      ],
      "metadata": {
        "id": "S_-EmkH8MvPO"
      },
      "id": "S_-EmkH8MvPO"
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/drive/MyDrive/RGCI_Lung_Cancer/LIDC-IDRI Dataset CT Images/CT/test/'\n",
        "output_dir = '/content/drive/MyDrive/LIDC-IDRI Dataset Segmented CT images/CT/test/'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "ccqmSSY7M2ng"
      },
      "id": "ccqmSSY7M2ng",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in os.listdir(input_dir):\n",
        "    if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        continue\n",
        "    img_path = os.path.join(input_dir, fname)\n",
        "    img = cv2.imread(img_path)\n",
        "    outputs = predictor(img)\n",
        "    instances = outputs['instances'].to('cpu')\n",
        "    masks = instances.pred_masks.numpy()\n",
        "\n",
        "    base_name = os.path.splitext(fname)[0]\n",
        "\n",
        "    for idx, mask in enumerate(masks):\n",
        "        seg_img = img * mask[:, :, None]\n",
        "        out_path = os.path.join(output_dir, f\"{base_name}.png\")\n",
        "        cv2.imwrite(out_path, seg_img)\n",
        "\n",
        "print('All images processed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqogv-T6M7Sy",
        "outputId": "4431a0b1-bb0c-49b3-8c35-83a9c3f0f55b"
      },
      "id": "gqogv-T6M7Sy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All images processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zei2-vf6Qr1t"
      },
      "id": "zei2-vf6Qr1t",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}